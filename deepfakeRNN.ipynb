{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import efficientnet.tfkeras as efn\n",
    "import re\n",
    "import numpy as np\n",
    "import random\n",
    "import ast\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.layers import (Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D,\n",
    "                          BatchNormalization, Input, Conv2D, GlobalAveragePooling2D,concatenate,Concatenate,multiply, LocallyConnected2D, Lambda)\n",
    "# from tensorflow.keras.applications.resnet_v2 import ResNet101V2\n",
    "from tf_explain.callbacks.grad_cam import GradCAMCallback\n",
    "import tensorflow_addons as tfa\n",
    "from TPUDataLoaderRNN import DataLoader\n",
    "import cv2\n",
    "tf.random.set_seed(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: smas255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: smas255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "# Create strategy from tpu\n",
    "tpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='smas255')\n",
    "tf.config.experimental_connect_to_cluster(tpu)\n",
    "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "strategy = tf.distribute.experimental.TPUStrategy(tpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS ={}\n",
    "# Configuration\n",
    "FLAGS['FOLD']='0'\n",
    "FLAGS['W'] = 224\n",
    "FLAGS['H'] = 224\n",
    "FLAGS['EPOCHS'] = 40\n",
    "FLAGS['LR'] = 0.00005\n",
    "FLAGS['WEIGHT_DECAY']=1e-4\n",
    "FLAGS['BATCH_SIZE'] =  32 * strategy.num_replicas_in_sync\n",
    "FLAGS['VAL_BATCH_SIZE'] = 16\n",
    "FLAGS['GCS_PATH'] = 'gs://deepfake_images/TFRecords/rnn/'\n",
    "FLAGS['GCS_LOGS'] = 'gs://deepfake_images/trainingLogs/'\n",
    "FLAGS['TRAINING_FILENAMES'] = tf.io.gfile.glob(FLAGS['GCS_PATH'] + 'fold{}/train/*.tfrec'.format(FLAGS['FOLD']))\n",
    "FLAGS['VALIDATION_FILENAMES'] = tf.io.gfile.glob(FLAGS['GCS_PATH'] + 'fold{}/val/*.tfrec'.format(FLAGS['FOLD']))\n",
    "FLAGS['TEST_FILENAMES'] = tf.io.gfile.glob(FLAGS['GCS_PATH'] + 'test/*.tfrec')\n",
    "\n",
    "random.shuffle(FLAGS['TRAINING_FILENAMES'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataLoader = DataLoader(FLAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_list = []\n",
    "# lbl_list = []\n",
    "# for img,lbl in dataLoader.get_gradcam_dataset():\n",
    "#     img_list = img.numpy()\n",
    "#     lbl_list = lbl.numpy()\n",
    "#     break\n",
    "# np.save('./data/img.npy',img_list)\n",
    "# np.save('./data/lbl.npy',lbl_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_list = np.load('./data/img.npy')\n",
    "# lbl_list = np.load('./data/lbl.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "def efficientModel(weights_path=None):\n",
    "    enet = efn.EfficientNetB0(\n",
    "        weights='noisy-student',\n",
    "        include_top=False,\n",
    "        pooling = 'avg'\n",
    "    )\n",
    "#     if weights_path!=None:\n",
    "#         model.load_weights('./b0.h5')\n",
    "    #output = tf.keras.layers.GlobalAveragePooling2D()(enet.output)\n",
    "    #output = tf.keras.layers.Dropout(0.2)(enet.output)\n",
    "    \n",
    "    inp=Input((16,FLAGS['H'],FLAGS['W'],3))\n",
    "    x=TimeDistributed(enet)(inp)\n",
    "    x = tf.keras.layers.Dropout(0.4)(x)\n",
    "    x = LSTM(64)(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    x = Dense(16, activation='elu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    output = Dense(1,activation='sigmoid')(x)\n",
    "    model = tf.keras.Model(inputs=inp, outputs=output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = efficientModel()\n",
    "#     model.load_weights('./rnn_b0.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 66008 training images, 16677 validation images, 257 Steps\n"
     ]
    }
   ],
   "source": [
    "FLAGS['NUM_TRAINING_IMAGES'] = dataLoader.count_data_items(FLAGS['TRAINING_FILENAMES'])\n",
    "FLAGS['NUM_VALIDATION_IMAGES'] = dataLoader.count_data_items(FLAGS['VALIDATION_FILENAMES'])\n",
    "FLAGS['STEPS_PER_EPOCH'] = FLAGS['NUM_TRAINING_IMAGES'] // FLAGS['BATCH_SIZE']\n",
    "FLAGS['VALIDATION_STEPS'] = FLAGS['NUM_VALIDATION_IMAGES'] // FLAGS['VAL_BATCH_SIZE']\n",
    "print('Dataset: {} training images, {} validation images, {} Steps'.format(\n",
    "    FLAGS['NUM_TRAINING_IMAGES'], FLAGS['NUM_VALIDATION_IMAGES'],FLAGS['STEPS_PER_EPOCH']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight={0:2.43284682,1:0.62934289}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warm up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warmup():\n",
    "    # warm up model\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    for i in range(-3,0):\n",
    "        model.layers[i].trainable = True\n",
    "    model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(),\n",
    "            #loss=macro_double_soft_f1,\n",
    "            #optimizer=tf.keras.optimizers.SGD(learning_rate= FLAGS['LR'],momentum=0.9,decay=FLAGS['WEIGHT_DECAY']),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "    model.fit(\n",
    "        dataLoader.get_training_dataset(), \n",
    "        steps_per_epoch=FLAGS['STEPS_PER_EPOCH'],\n",
    "        class_weight=class_weight,\n",
    "        epochs=1)\n",
    "    #model.save_weights('./rnn_b0.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 257 steps\n",
      "257/257 [==============================] - 481s 2s/step - loss: 0.6939 - accuracy: 0.5464\n"
     ]
    }
   ],
   "source": [
    "WARM_UP = True\n",
    "if WARM_UP:\n",
    "    warmup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lrfn(lr_start=0.00001, lr_max=0.000075, \n",
    "               lr_min=0.000001, lr_rampup_epochs=5, \n",
    "               lr_sustain_epochs=3, lr_exp_decay=.8):\n",
    "    lr_max = lr_max * strategy.num_replicas_in_sync\n",
    "\n",
    "    def lrfn(epoch):\n",
    "        if epoch < lr_rampup_epochs:\n",
    "            lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start\n",
    "        elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n",
    "            lr = lr_max\n",
    "        else:\n",
    "            lr = (lr_max - lr_min) * lr_exp_decay**(epoch - lr_rampup_epochs - lr_sustain_epochs) + lr_min\n",
    "        return lr\n",
    "    \n",
    "    return lrfn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 257 steps\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "Epoch 1/40\n",
      "256/257 [============================>.] - ETA: 1s - loss: 0.6940 - accuracy: 0.4645WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 440s 2s/step - loss: 0.6940 - accuracy: 0.4646\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.000128.\n",
      "Epoch 2/40\n",
      "256/257 [============================>.] - ETA: 1s - loss: 0.5488 - accuracy: 0.6963\n",
      "Epoch 00002: val_loss improved from inf to 0.48667, saving model to gs://hamid_kaggles/model_checkpoints/\n",
      "257/257 [==============================] - 488s 2s/step - loss: 0.5483 - accuracy: 0.6964 - val_loss: 0.4867 - val_accuracy: 0.8317\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.00024599999999999996.\n",
      "Epoch 3/40\n",
      "256/257 [============================>.] - ETA: 1s - loss: 0.3212 - accuracy: 0.8497WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 344s 1s/step - loss: 0.3209 - accuracy: 0.8500\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.00036399999999999996.\n",
      "Epoch 4/40\n",
      "256/257 [============================>.] - ETA: 1s - loss: 0.2185 - accuracy: 0.8970\n",
      "Epoch 00004: val_loss did not improve from 0.48667\n",
      "257/257 [==============================] - 371s 1s/step - loss: 0.2184 - accuracy: 0.8971 - val_loss: 0.4926 - val_accuracy: 0.8712\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.00048199999999999995.\n",
      "Epoch 5/40\n",
      "256/257 [============================>.] - ETA: 1s - loss: 0.1698 - accuracy: 0.9296WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 349s 1s/step - loss: 0.1695 - accuracy: 0.9297\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0006.\n",
      "Epoch 6/40\n",
      "256/257 [============================>.] - ETA: 1s - loss: 0.1465 - accuracy: 0.9371\n",
      "Epoch 00006: val_loss improved from 0.48667 to 0.42162, saving model to gs://hamid_kaggles/model_checkpoints/\n",
      "257/257 [==============================] - 371s 1s/step - loss: 0.1466 - accuracy: 0.9373 - val_loss: 0.4216 - val_accuracy: 0.8904\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.0006.\n",
      "Epoch 7/40\n",
      "256/257 [============================>.] - ETA: 1s - loss: 0.1141 - accuracy: 0.9489WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 347s 1s/step - loss: 0.1141 - accuracy: 0.9486\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.0006.\n",
      "Epoch 8/40\n",
      " 90/257 [=========>....................] - ETA: 3:49 - loss: 0.1026 - accuracy: 0.9538"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "radam = tfa.optimizers.RectifiedAdam(lr=FLAGS['LR'])\n",
    "# opt = tfa.optimizers.Lookahead(radam, sync_period=6, slow_step_size=0.5)\n",
    "lrfn = build_lrfn()\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=1) \n",
    "model.compile(\n",
    "        optimizer=radam,#tf.keras.optimizers.Adam(lr=FLAGS['LR'], clipnorm=1.),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "#lr_schedule = OneCycleScheduler(FLAGS['LR'], FLAGS['STEPS_PER_EPOCH'])\n",
    "# lr_schedule = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.25, patience=2, \n",
    "#                                    verbose=1, mode='auto', min_delta=0.0001)\n",
    "#tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=FLAGS['GCS_LOGS'], update_freq=10)\n",
    "# gradcam_callback = GradCAMCallback(\n",
    "#         validation_data=(img_list,lbl_list),\n",
    "#         layer_name=\"top_conv\",\n",
    "#         class_index=0,\n",
    "#         output_dir=FLAGS['GCS_LOGS']\n",
    "#     )\n",
    "#lr_schedule = OneCycleScheduler(FLAGS['LR'], FLAGS['STEPS_PER_EPOCH'])\n",
    "#lr_schedule = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=1)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath='gs://hamid_kaggles/model_checkpoints/',\n",
    "                                                 monitor='val_loss',\n",
    "                                                 verbose=1,\n",
    "                                                 save_best_only=True,\n",
    "                                                 save_weights_only=True\n",
    "                                                 )\n",
    "history = model.fit(\n",
    "    dataLoader.get_training_dataset(), \n",
    "    steps_per_epoch=FLAGS['STEPS_PER_EPOCH'],\n",
    "    epochs=FLAGS['EPOCHS'], \n",
    "    callbacks=[lr_schedule,cp_callback],\n",
    "    class_weight=class_weight,\n",
    "    validation_data=dataLoader.get_validation_dataset(),\n",
    "    validation_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./b3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = efficientAttention()\n",
    "    model.load_weights('gs://hamid_kaggles/model_checkpoints/')\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(lr=FLAGS['LR'], clipnorm=1.),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS['NUM_TEST_IMAGES'] = dataLoader.count_data_items(FLAGS['TEST_FILENAMES'])\n",
    "\n",
    "FLAGS['TEST_STEPS_PER_EPOCH'] = FLAGS['NUM_TEST_IMAGES'] // FLAGS['BATCH_SIZE']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 16s 1s/step - loss: 0.2988 - accuracy: 0.8627\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(dataLoader.get_test_dataset(), \n",
    "    steps=FLAGS['TEST_STEPS_PER_EPOCH'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-03-08 02:48:41--  https://tpu.googleapis.com/v1/projects/deepfake-267708/locations/europe-west4-a/nodes/tpu-32?alt=json\n",
      "Resolving tpu.googleapis.com (tpu.googleapis.com)... 108.177.119.95, 2a00:1450:4013:c04::5f\n",
      "Connecting to tpu.googleapis.com (tpu.googleapis.com)|108.177.119.95|:443... connected.\n",
      "HTTP request sent, awaiting response... 403 Forbidden\n",
      "2020-03-08 02:48:41 ERROR 403: Forbidden.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://tpu.googleapis.com/v1/projects/deepfake-267708/locations/europe-west4-a/nodes/tpu-32?alt=json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-17 00:55:59.249643: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory\n",
      "2020-03-17 00:55:59.249754: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory\n",
      "2020-03-17 00:55:59.249779: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2020-03-17 00:56:00.731180: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2020-03-17 00:56:00.731232: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2020-03-17 00:56:00.731301: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (smas255): /proc/driver/nvidia/version does not exist\n",
      "2020-03-17 00:56:00.946925: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2020-03-17 00:56:00.954481: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000129999 Hz\n",
      "2020-03-17 00:56:00.954823: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560ff777d780 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-03-17 00:56:00.954860: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-03-17 00:56:00.961828: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job worker -> {0 -> 10.151.73.221:8470, 1 -> 10.151.73.218:8470, 2 -> 10.151.73.220:8470, 3 -> 10.151.73.219:8470}\n",
      "2020-03-17 00:56:00.961876: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:34255}\n",
      "2020-03-17 00:56:00.991569: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job worker -> {0 -> 10.151.73.221:8470, 1 -> 10.151.73.218:8470, 2 -> 10.151.73.220:8470, 3 -> 10.151.73.219:8470}\n",
      "2020-03-17 00:56:00.991648: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:34255}\n",
      "2020-03-17 00:56:00.993041: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:390] Started server with target: grpc://localhost:34255\n",
      "Dataset: 348162 training images, 81958 validation images, 85 Steps\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"deepfake_training.py\", line 129, in <module>\n",
      "    hist = training()\n",
      "  File \"deepfake_training.py\", line 53, in training\n",
      "    model = efficientAttention()\n",
      "  File \"deepfake_training.py\", line 21, in efficientAttention\n",
      "    include_top=False\n",
      "  File \"/home/mashhs/anaconda3/envs/img/lib/python3.6/site-packages/efficientnet/__init__.py\", line 57, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/mashhs/anaconda3/envs/img/lib/python3.6/site-packages/efficientnet/model.py\", line 530, in EfficientNetB3\n",
      "    **kwargs\n",
      "  File \"/home/mashhs/anaconda3/envs/img/lib/python3.6/site-packages/efficientnet/model.py\", line 372, in EfficientNet\n",
      "    prefix='block{}a_'.format(idx + 1))\n",
      "  File \"/home/mashhs/anaconda3/envs/img/lib/python3.6/site-packages/efficientnet/model.py\", line 235, in mb_conv_block\n",
      "    x = layers.BatchNormalization(axis=bn_axis, name=prefix + 'project_bn')(x)\n",
      "  File \"/home/mashhs/anaconda3/envs/img/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 773, in __call__\n",
      "    outputs = call_fn(cast_inputs, *args, **kwargs)\n",
      "  File \"/home/mashhs/anaconda3/envs/img/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/normalization.py\", line 695, in call\n",
      "    outputs = self._fused_batch_norm(inputs, training=training)\n",
      "  File \"/home/mashhs/anaconda3/envs/img/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/normalization.py\", line 553, in _fused_batch_norm\n",
      "    training, _fused_batch_norm_training, _fused_batch_norm_inference)\n",
      "  File \"/home/mashhs/anaconda3/envs/img/lib/python3.6/site-packages/tensorflow_core/python/keras/utils/tf_utils.py\", line 59, in smart_cond\n",
      "    pred, true_fn=true_fn, false_fn=false_fn, name=name)\n",
      "  File \"/home/mashhs/anaconda3/envs/img/lib/python3.6/site-packages/tensorflow_core/python/framework/smart_cond.py\", line 59, in smart_cond\n",
      "    name=name)\n",
      "  File \"/home/mashhs/anaconda3/envs/img/lib/python3.6/site-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/mashhs/anaconda3/envs/img/lib/python3.6/site-packages/tensorflow_core/python/ops/control_flow_ops.py\", line 1174, in cond\n",
      "    return cond_v2.cond_v2(pred, true_fn, false_fn, name)\n",
      "  File \"/home/mashhs/anaconda3/envs/img/lib/python3.6/site-packages/tensorflow_core/python/ops/cond_v2.py\", line 100, in cond_v2\n",
      "    name=scope)\n",
      "  File \"/home/mashhs/anaconda3/envs/img/lib/python3.6/site-packages/tensorflow_core/python/ops/cond_v2.py\", line 270, in _build_cond\n",
      "    util.create_new_tf_function(false_graph),\n",
      "  File \"/home/mashhs/anaconda3/envs/img/lib/python3.6/site-packages/tensorflow_core/python/ops/control_flow_util_v2.py\", line 63, in create_new_tf_function\n",
      "    func_graph.name, func_graph, func_graph.inputs, func_graph.outputs, {})\n",
      "  File \"/home/mashhs/anaconda3/envs/img/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\", line 466, in __init__\n",
      "    function_def.ParseFromString(compat.as_bytes(proto_data))\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python deepfake_training.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class CosineAnnealer:\n",
    "    \n",
    "    def __init__(self, start, end, steps):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.steps = steps\n",
    "        self.n = 0\n",
    "        \n",
    "    def step(self):\n",
    "        self.n += 1\n",
    "        cos = np.cos(np.pi * (self.n / self.steps)) + 1\n",
    "        return self.end + (self.start - self.end) / 2. * cos\n",
    "\n",
    "\n",
    "class OneCycleScheduler(Callback):\n",
    "\n",
    "\n",
    "    def __init__(self, lr_max, steps, mom_min=0.85, mom_max=0.95, phase_1_pct=0.3, div_factor=25.):\n",
    "        super(OneCycleScheduler, self).__init__()\n",
    "        lr_min = lr_max / div_factor\n",
    "        final_lr = lr_max / (div_factor * 1e4)\n",
    "        phase_1_steps = steps * phase_1_pct\n",
    "        phase_2_steps = steps - phase_1_steps\n",
    "        \n",
    "        self.phase_1_steps = phase_1_steps\n",
    "        self.phase_2_steps = phase_2_steps\n",
    "        self.phase = 0\n",
    "        self.step = 0\n",
    "        \n",
    "        self.phases = [[CosineAnnealer(lr_min, lr_max, phase_1_steps), CosineAnnealer(mom_max, mom_min, phase_1_steps)], \n",
    "                 [CosineAnnealer(lr_max, final_lr, phase_2_steps), CosineAnnealer(mom_min, mom_max, phase_2_steps)]]\n",
    "        \n",
    "        self.lrs = []\n",
    "        self.moms = []\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.phase = 0\n",
    "        self.step = 0\n",
    "\n",
    "        self.set_lr(self.lr_schedule().start)\n",
    "        self.set_momentum(self.mom_schedule().start)\n",
    "        \n",
    "    def on_train_batch_begin(self, batch, logs=None):\n",
    "        self.lrs.append(self.get_lr())\n",
    "        self.moms.append(self.get_momentum())\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        self.step += 1\n",
    "        if self.step >= self.phase_1_steps:\n",
    "            self.phase = 1\n",
    "            \n",
    "        self.set_lr(self.lr_schedule().step())\n",
    "        self.set_momentum(self.mom_schedule().step())\n",
    "        \n",
    "    def get_lr(self):\n",
    "        try:\n",
    "            return tf.keras.backend.get_value(self.model.optimizer.lr)\n",
    "        except AttributeError:\n",
    "            return None\n",
    "        \n",
    "    def get_momentum(self):\n",
    "        try:\n",
    "            return tf.keras.backend.get_value(self.model.optimizer.momentum)\n",
    "        except AttributeError:\n",
    "            return None\n",
    "        \n",
    "    def set_lr(self, lr):\n",
    "        try:\n",
    "            tf.keras.backend.set_value(self.model.optimizer.lr, lr)\n",
    "        except AttributeError:\n",
    "            pass # ignore\n",
    "        \n",
    "    def set_momentum(self, mom):\n",
    "        try:\n",
    "            tf.keras.backend.set_value(self.model.optimizer.momentum, mom)\n",
    "        except AttributeError:\n",
    "            pass # ignore\n",
    "\n",
    "    def lr_schedule(self):\n",
    "        return self.phases[self.phase][0]\n",
    "    \n",
    "    def mom_schedule(self):\n",
    "        return self.phases[self.phase][1]\n",
    "    \n",
    "    def plot(self):\n",
    "        ax = plt.subplot(1, 2, 1)\n",
    "        ax.plot(self.lrs)\n",
    "        ax.set_title('Learning Rate')\n",
    "        ax = plt.subplot(1, 2, 2)\n",
    "        ax.plot(self.moms)\n",
    "        ax.set_title('Momentum')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
